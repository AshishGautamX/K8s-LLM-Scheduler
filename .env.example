# Environment variables for AI Kubernetes Scheduler
# Copy this file to .env and fill in your values

# HuggingFace API Token (required)
# Get your token from: https://huggingface.co/settings/tokens
HUGGINGFACE_TOKEN=your_token_here

# Scheduler Configuration
SCHEDULER_NAME=ai-llama-scheduler
LOG_LEVEL=INFO
LOG_FORMAT=json

# LLM Configuration
LLM_MODEL=meta-llama/Llama-3.3-70B-Instruct
LLM_ENDPOINT=https://router.huggingface.co
LLM_MAX_RETRIES=3
LLM_TIMEOUT=60

# Cache Configuration
ENABLE_CACHE=true
CACHE_TTL=300

# Metrics Configuration
ENABLE_METRICS=true
METRICS_PORT=9090
