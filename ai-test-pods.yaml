apiVersion: v1
kind: Pod
metadata:
  name: ai-test-pod-1
  namespace: default
spec:
  schedulerName: ai-llama-scheduler  # Updated for Llama-3.3-70B
  containers:
  - name: nginx
    image: nginx:alpine
    resources:
      requests:
        memory: "256Mi"
        cpu: "250m"
---
apiVersion: v1
kind: Pod
metadata:
  name: ai-test-pod-2
  namespace: default
spec:
  schedulerName: ai-llama-scheduler  # Updated for Llama-3.3-70B
  containers:
  - name: nginx
    image: nginx:alpine
    resources:
      requests:
        memory: "512Mi"
        cpu: "500m"
---
apiVersion: v1
kind: Pod
metadata:
  name: ai-test-pod-3
  namespace: default
spec:
  schedulerName: ai-llama-scheduler  # Updated for Llama-3.3-70B
  containers:
  - name: nginx
    image: nginx:alpine
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"